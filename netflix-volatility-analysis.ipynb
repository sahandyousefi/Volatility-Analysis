{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12290884,"sourceType":"datasetVersion","datasetId":7746348}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T15:29:31.157798Z","iopub.execute_input":"2025-07-06T15:29:31.158441Z","iopub.status.idle":"2025-07-06T15:29:31.170847Z","shell.execute_reply.started":"2025-07-06T15:29:31.158413Z","shell.execute_reply":"2025-07-06T15:29:31.170069Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/netflix-stock-price-history/Netflix_stock_data.csv\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/netflix-stock-price-history/Netflix_stock_data.csv')\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T15:29:31.172473Z","iopub.execute_input":"2025-07-06T15:29:31.172986Z","iopub.status.idle":"2025-07-06T15:29:31.198186Z","shell.execute_reply.started":"2025-07-06T15:29:31.172961Z","shell.execute_reply":"2025-07-06T15:29:31.197388Z"}},"outputs":[{"name":"stdout","text":"         Date     Close      High       Low      Open     Volume\n0  2002-05-23  1.196429  1.242857  1.145714  1.156429  104790000\n1  2002-05-24  1.210000  1.225000  1.197143  1.214286   11104800\n2  2002-05-28  1.157143  1.232143  1.157143  1.213571    6609400\n3  2002-05-29  1.103571  1.164286  1.085714  1.164286    6757800\n4  2002-05-30  1.071429  1.107857  1.071429  1.107857   10154200\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# 1. Data Insight","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T15:29:31.199196Z","iopub.execute_input":"2025-07-06T15:29:31.199444Z","iopub.status.idle":"2025-07-06T15:29:31.204402Z","shell.execute_reply.started":"2025-07-06T15:29:31.199418Z","shell.execute_reply":"2025-07-06T15:29:31.203810Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(5810, 6)"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T15:29:31.205069Z","iopub.execute_input":"2025-07-06T15:29:31.205278Z","iopub.status.idle":"2025-07-06T15:29:31.235849Z","shell.execute_reply.started":"2025-07-06T15:29:31.205262Z","shell.execute_reply":"2025-07-06T15:29:31.235147Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"             Close         High          Low         Open        Volume\ncount  5810.000000  5810.000000  5810.000000  5810.000000  5.810000e+03\nmean    174.277189   176.778673   171.606167   174.184463  1.513608e+07\nstd     238.038218   241.092964   234.690133   237.807511  1.836569e+07\nmin       0.372857     0.410714     0.346429     0.377857  2.856000e+05\n25%       4.307500     4.406428     4.226071     4.310714  5.385225e+06\n50%      47.330715    48.094999    46.490715    47.347857  9.366850e+06\n75%     319.687500   324.845009   313.472504   319.279991  1.803375e+07\nmax    1279.109985  1298.000000  1273.810059  1286.839966  3.234140e+08","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Close</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Open</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5810.000000</td>\n      <td>5810.000000</td>\n      <td>5810.000000</td>\n      <td>5810.000000</td>\n      <td>5.810000e+03</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>174.277189</td>\n      <td>176.778673</td>\n      <td>171.606167</td>\n      <td>174.184463</td>\n      <td>1.513608e+07</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>238.038218</td>\n      <td>241.092964</td>\n      <td>234.690133</td>\n      <td>237.807511</td>\n      <td>1.836569e+07</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.372857</td>\n      <td>0.410714</td>\n      <td>0.346429</td>\n      <td>0.377857</td>\n      <td>2.856000e+05</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>4.307500</td>\n      <td>4.406428</td>\n      <td>4.226071</td>\n      <td>4.310714</td>\n      <td>5.385225e+06</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>47.330715</td>\n      <td>48.094999</td>\n      <td>46.490715</td>\n      <td>47.347857</td>\n      <td>9.366850e+06</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>319.687500</td>\n      <td>324.845009</td>\n      <td>313.472504</td>\n      <td>319.279991</td>\n      <td>1.803375e+07</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1279.109985</td>\n      <td>1298.000000</td>\n      <td>1273.810059</td>\n      <td>1286.839966</td>\n      <td>3.234140e+08</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T15:29:31.237480Z","iopub.execute_input":"2025-07-06T15:29:31.237721Z","iopub.status.idle":"2025-07-06T15:29:31.244939Z","shell.execute_reply.started":"2025-07-06T15:29:31.237704Z","shell.execute_reply":"2025-07-06T15:29:31.244297Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Date      0\nClose     0\nHigh      0\nLow       0\nOpen      0\nVolume    0\ndtype: int64"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"# Set data as index\ndf.set_index('Date',inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T15:29:31.245735Z","iopub.execute_input":"2025-07-06T15:29:31.246233Z","iopub.status.idle":"2025-07-06T15:29:31.258157Z","shell.execute_reply.started":"2025-07-06T15:29:31.246214Z","shell.execute_reply":"2025-07-06T15:29:31.257286Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"# 2. Vizualization","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T15:29:31.259016Z","iopub.execute_input":"2025-07-06T15:29:31.259250Z","iopub.status.idle":"2025-07-06T15:29:31.271307Z","shell.execute_reply.started":"2025-07-06T15:29:31.259229Z","shell.execute_reply":"2025-07-06T15:29:31.270647Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Line plot - Close price\nplt.figure(figsize=(14,6))\nplt.plot(df['Close'],label='Close Price')\nplt.title('Netflix Close Price Over Time')\nplt.xlabel(\"Date\")\nplt.ylabel(\"Close Price\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T15:29:31.272138Z","iopub.execute_input":"2025-07-06T15:29:31.272375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.heatmap(df.corr(),annot=True,cmap='coolwarm')\nplt.title('Correlation Heatmap')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Histogram of daily returns\ndf['Daily_Return'] = df['Close'].pct_change()\nplt.figure(figsize=(10, 5))\nsns.histplot(df['Daily_Return'].dropna(), bins=100, kde=True)\nplt.title(\"Histogram of Daily Returns\")\nplt.xlabel(\"Daily Return\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Volatility Analysis and Risk Estimation","metadata":{}},{"cell_type":"code","source":"# Moving averages\ndf['MA50'] = df['Close'].rolling(window=50).mean()\ndf['MA200'] = df['Close'].rolling(window=200).mean()\n\nplt.figure(figsize=(14, 6))\nplt.plot(df['Close'], label='Close')\nplt.plot(df['MA50'], label='50-day MA')\nplt.plot(df['MA200'], label='200-day MA')\nplt.title(\"Netflix Close Price with Moving Averages\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Price\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## **Steps:**\n\n---\n\n### 1. **Calculate Daily Returns**\n\n$$\n\\text{Return}_t = \\frac{P_t - P_{t-1}}{P_{t-1}}\n$$\n\n---\n\n### 2. **Rolling Volatility**\n\n$$\n\\text{Volatility}_t = \\text{STD}(\\text{Return}_{t-n \\text{ to } t})\n$$\n\n---\n\n### 3. **Bollinger Bands**\n\n$$\n\\text{Upper Band} = \\text{MA}_{20} + 2 \\times \\text{STD}_{20}, \\quad \n\\text{Lower Band} = \\text{MA}_{20} - 2 \\times \\text{STD}_{20}\n$$\n\n---\n\n### 4. **Value at Risk (VaR)**\n\n$$\n\\text{VaR}_{95\\%} = \\mu - 1.65 \\times \\sigma\n$$\n\n*($\\mu$ = mean return, $\\sigma$ = std return)*\n\n---\n\n### 5. **GARCH model for volatility clustering**\n","metadata":{}},{"cell_type":"code","source":"# 2. Rolling Volatility (30-day window)\ndf['Rolling_STD_30'] = df['Daily_Return'].rolling(window=30).std()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot Rolling Volatility\nplt.figure(figsize=(14, 6))\nplt.plot(df['Rolling_STD_30'], label='30-Day Rolling Volatility', color='orange')\nplt.title('Netflix Stock 30-Day Rolling Volatility')\nplt.xlabel('Date')\nplt.ylabel('Volatility')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Bollinger Bands\ndf['MA20'] = df['Close'].rolling(window=20).mean()\ndf['STD20'] = df['Close'].rolling(window=20).std()\ndf['Upper_Band'] = df['MA20'] + 2 * df['STD20']\ndf['Lower_Band'] = df['MA20'] - 2 * df['STD20']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot Bollinger Bands\nplt.figure(figsize=(14, 6))\nplt.plot(df['Close'], label='Close Price')\nplt.plot(df['Upper_Band'], label='Upper Band', linestyle='--')\nplt.plot(df['Lower_Band'], label='Lower Band', linestyle='--')\nplt.title('Bollinger Bands (20-day window)')\nplt.xlabel('Date')\nplt.ylabel('Price')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Value at Risk (95% confidence)\nmean_ret = df['Daily_Return'].mean()\nstd_ret = df['Daily_Return'].std()\nVaR_95 = mean_ret - 1.65 * std_ret\nprint(f\"Value at Risk (95% Confidence): {VaR_95:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ðŸ“‰ Value at Risk (VaR) â€“ Interpretation\n\nWe calculated the **95% Value at Risk (VaR)** for Netflix daily returns using:\n\n$$\n\\text{VaR}_{95\\%} = \\mu - 1.65 \\cdot \\sigma\n$$\n\nWhere:\n- $\\mu$ is the **mean** of daily returns\n- $\\sigma$ is the **standard deviation** of daily returns\n- 1.65 corresponds to the Z-score for 95% confidence\n\n---\n\n### âœ… Result:\n```python\nValue at Risk (95% Confidence): -0.0555\n\nThere is a 95% probability that Netflixâ€™s daily return will not drop below -5.55% on any given day.\n\nIn other words, we expect to lose more than 5.55% on a single day only 5% of the time (1 in 20 trading days).","metadata":{}},{"cell_type":"markdown","source":"# ðŸ“˜ GARCH (Generalized Autoregressive Conditional Heteroskedasticity)\n\n---\n\n## ðŸ”¹ Why Use GARCH?\n\nGARCH is used to **model and forecast volatility** in time series data, especially in financial markets. It captures:\n\n- **Volatility clustering**: High-volatility periods are followed by high-volatility, and low by low.\n- **Time-varying variance**: Unlike constant variance in standard models, GARCH adapts variance over time.\n\n---\n\n## ðŸ”¹ GARCH(1,1) Formula\n\n$$\n\\sigma_t^2 = \\omega + \\alpha \\cdot \\epsilon_{t-1}^2 + \\beta \\cdot \\sigma_{t-1}^2\n$$\n\nWhere:\n\n- $\\sigma_t^2$ = forecasted variance at time $t$\n- $\\epsilon_{t-1}^2$ = previous dayâ€™s squared residual (shock)\n- $\\sigma_{t-1}^2$ = previous dayâ€™s variance\n- $\\omega, \\alpha, \\beta$ = parameters to estimate\n\n---\n\n## ðŸ”¹ Interpretation\n\n- If $\\alpha + \\beta < 1$: volatility is **mean-reverting**\n- High $\\alpha$: volatility responds quickly to market shocks\n- High $\\beta$: volatility is **persistent** (long-lasting effects)\n\n---\n\n## ðŸ”¹ Use Cases\n\n- Forecasting risk\n- Calculating Value at Risk (VaR)\n- Financial modeling and option pricing\n- Portfolio volatility estimation","metadata":{}},{"cell_type":"code","source":"!pip install arch\nfrom arch import arch_model\n\n# Drop missing values\nreturns = df['Daily_Return'].dropna() * 100  # Convert to percentage for GARCH\n\n# Fit GARCH(1,1) model\nmodel = arch_model(returns, vol='Garch', p=1, q=1)\ngarch_fit = model.fit(disp='off')\n\n# Forecast variance\nforecast = garch_fit.forecast(horizon=5)\ngarch_vol = np.sqrt(forecast.variance.iloc[-1])\n\nprint(\"GARCH(1,1) Forecasted Volatility for next 5 days:\")\nprint(garch_vol)\n\n# Plot conditional volatility\nplt.figure(figsize=(14, 6))\nplt.plot(garch_fit.conditional_volatility, label='Conditional Volatility')\nplt.title('GARCH(1,1) Conditional Volatility')\nplt.xlabel('Date')\nplt.ylabel('Volatility')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n### ðŸ“Œ Interpretation:\n\n- These values represent the **forecasted standard deviation (%) of daily returns**.\n- The volatility is expected to stay between **2.42% and 2.45%** over the next 5 days.\n- This implies **moderate and stable market uncertainty** around Netflix stock in the short term.\n\n---\n\nGARCH is particularly useful when volatility is **not constant** and tends to **cluster**â€”just like we observe in financial time series data.\n","metadata":{}},{"cell_type":"markdown","source":"# Conclusion and Summary\n\n## âœ… Project Summary & Closing Notes\n\nIn this time series project on **Netflix Stock Analysis**, we:\n\n- âœ… Performed **Exploratory Data Analysis** (EDA) and visualized trends using line plots, moving averages, and return histograms.\n- âœ… Calculated **Volatility Indicators** like rolling standard deviation and **Bollinger Bands** to monitor risk levels.\n- âœ… Estimated **Value at Risk (VaR)** at a 95% confidence level to quantify downside risk.\n- âœ… Applied the **GARCH(1,1)** model to forecast short-term volatility and capture volatility clustering behavior in the returns.\n\n---\n\n### Key Takeaways:\n\n- Netflix stock shows **volatility clustering**, making GARCH models a good fit.\n- The estimated **VaR of ~-5.5%** helps define worst-case daily losses with 95% confidence.\n- **Forecasted volatility (GARCH)** around ~2.4% signals moderate short-term uncertainty.\n\n\n## Thanks for reviewing this project!  \n","metadata":{}}]}